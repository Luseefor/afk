---
title: LLMs Overview
description: Provider-driven llms runtime and builder workflow.
---

## LLM runtime map

```mermaid
flowchart LR
    Builder[LLMBuilder] --> Client[LLMClient]
    Client --> ProviderRegistry[Provider registry]
    ProviderRegistry --> Transport[Provider transport]
    Client --> Policies[Runtime policies]
```

## Start here

```python
from afk.llms import LLMBuilder

client = (
    LLMBuilder()
    .provider("openai")
    .model("gpt-4.1-mini")
    .profile("production")
    .build()
)
```

## Mental model

- provider chooses transport
- runtime policies choose execution behavior
- caller code consumes normalized contracts only
