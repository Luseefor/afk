---
title: Contracts
description: Public contracts for llm providers, runtime policies, and requests.
---

## Core Contracts

- Request/response: `LLMRequest`, `LLMResponse`, `EmbeddingRequest`, `EmbeddingResponse`.
- Provider contracts: `LLMProvider`, `LLMTransport`, `ProviderSettingsSchema`.
- Runtime policies:
  - `RetryPolicy`
  - `TimeoutPolicy`
  - `RateLimitPolicy`
  - `CircuitBreakerPolicy`
  - `HedgingPolicy`
  - `CachePolicy`
  - `CoalescingPolicy`
  - `RoutePolicy`

## LLMRequest Extensions

`LLMRequest` now supports enterprise runtime overrides:

- `retry_policy`
- `timeout_policy`
- `stream_idle_timeout_s`
- `route_policy`
- `cache_policy`

## Runtime Policy Defaults

You can set policy defaults at client construction time with `LLMBuilder.profile(...)`
or override per request through `LLMRequest`.

```python
from afk.llms import LLMBuilder, LLMRequest, Message, RetryPolicy, TimeoutPolicy

llm = LLMBuilder().provider("openai").profile("production").build()

resp = await llm.chat(
    LLMRequest(
        model="gpt-4.1-mini",
        messages=[Message(role="user", content="hello")],
        retry_policy=RetryPolicy(max_retries=2),
        timeout_policy=TimeoutPolicy(request_timeout_s=15.0, stream_idle_timeout_s=20.0),
    )
)
```

## Stability Rules

- Public interfaces use normalized AFK types only.
- Provider-native objects must not leak past `LLMTransport`.
- Observer/telemetry failures are non-fatal.
